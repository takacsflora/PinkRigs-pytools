{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataSet structure\n",
    "The main thing to know about the PinkRigs organisation is that we store two types of data about the experiments: \n",
    "- metadata (CSVs) summarising each animal and experiemntal session\n",
    "- experimental session data\n",
    "Typically when you run analysis on the PinkRigs data you will need to do the following: \n",
    "1) query the metadata to make sure you included all the data that fits your requrements\n",
    "2) load in the details (events,spikes,cameras) of the datasets that you have selected\n",
    "\n",
    "\n",
    "### Querying experiments\n",
    "You can query the experiements using the `query.queryCSV` module, e.g.:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinkrigs_tools.dataset.query import queryCSV\n",
    "\n",
    "exp = queryCSV(\n",
    "  subject='AV043',\n",
    "  expDate='2024-03-14:2024-03-24', \n",
    "  expDef = 'multiSpaceWorld_checker_training',\n",
    "  )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data\n",
    "You can also direcrly query and then load the ONE folder content in one line using `load_data`. To specify the ONE folder content to load, you need to give a nested dictionary to the `data_name_dict` argument of the `load_data`. The nesting follows the ONE data structure `{collection:{'object':'attribute'}}`. For example: \n",
    "#### Events data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinkrigs_tools.dataset.query import load_data\n",
    "\n",
    "# define parameters of your query\n",
    "exp_kwargs = {\n",
    "    'subject': ['AV043'],\n",
    "    'expDate': '2024-03-14:2024-03-15',\n",
    "    }\n",
    "\n",
    "# define the ONE data to load\n",
    "data_name_dict = { 'events': {'_av_trials': 'table'}}\n",
    "recordings = load_data(data_name_dict=data_name_dict,**exp_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spikes data\n",
    "(this operation is the slowest! So, in order to avoid loading in unwanted data, you should probably query the data first and then only load in spike data for datasets that you ensured you want to use in your analysis.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ephys_dict = {'spikes':'all','clusters':'all'}\n",
    "# both probes \n",
    "data_name_dict = {'probe0':ephys_dict,'probe1':ephys_dict} \n",
    "recordings = load_data(data_name_dict=data_name_dict,**exp_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Camera data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cameras = ['frontCam','sideCam','eyeCam']\n",
    "data_name_dict = {cam:{'camera':['times','ROIMotionEnergy']} for cam in cameras}\n",
    "recordings = load_data(data_name_dict=data_name_dict,**exp_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively you can also first query the data using `queryCSV`, subset your DataFrame as you wish, and load the ONE object only on your subset using 'load_data'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "recordings = load_data(recordings=exp.iloc[0:1], data_name_dict = {'events':{'_av_trials':'all'}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or just load every data together by inputting `all-default` as the `data_name_dict`! This will load `events`,`probe0`,`probe1`,`frontCam`,`eyeCam` and `sideCam` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define which data you need\n",
    "recordings = load_data(\n",
    "    subject = 'AV043',\n",
    "    expDate  = '2024-03-14',\n",
    "    data_name_dict='all-default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>expDate</th>\n",
       "      <th>expNum</th>\n",
       "      <th>expDef</th>\n",
       "      <th>expDuration</th>\n",
       "      <th>rigName</th>\n",
       "      <th>existBlock</th>\n",
       "      <th>existTimeline</th>\n",
       "      <th>existFrontCam</th>\n",
       "      <th>existSideCam</th>\n",
       "      <th>existEyeCam</th>\n",
       "      <th>...</th>\n",
       "      <th>expFolder</th>\n",
       "      <th>ephysPathProbe0</th>\n",
       "      <th>ephysPathProbe1</th>\n",
       "      <th>subject</th>\n",
       "      <th>events</th>\n",
       "      <th>probe0</th>\n",
       "      <th>probe1</th>\n",
       "      <th>frontCam</th>\n",
       "      <th>sideCam</th>\n",
       "      <th>eyeCam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-03-14</td>\n",
       "      <td>1</td>\n",
       "      <td>multiSpaceWorld_checker_training</td>\n",
       "      <td>3576</td>\n",
       "      <td>zelda-stim1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>\\\\zortex.cortexlab.net\\Subjects\\AV043\\2024-03-...</td>\n",
       "      <td>\\\\zortex.cortexlab.net\\Subjects\\AV043\\2024-03-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AV043</td>\n",
       "      <td>{'_av_trials': {'is_blankTrial': [False, False...</td>\n",
       "      <td>{'spikes': {'amps': [0.0088954335, 0.001937999...</td>\n",
       "      <td>{'spikes': {}, 'clusters': {}}</td>\n",
       "      <td>{'camera': {'times': [-13.885303461488334, -13...</td>\n",
       "      <td>{'camera': {'times': [-13.9500134846031, -13.9...</td>\n",
       "      <td>{'camera': {'ROIMotionEnergy': [119602.0, 1033...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-03-14</td>\n",
       "      <td>2</td>\n",
       "      <td>AVPassive_ckeckerboard_postactive</td>\n",
       "      <td>3386</td>\n",
       "      <td>zelda-stim1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>\\\\zortex.cortexlab.net\\Subjects\\AV043\\2024-03-...</td>\n",
       "      <td>\\\\zortex.cortexlab.net\\Subjects\\AV043\\2024-03-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AV043</td>\n",
       "      <td>{'_av_trials': {'is_blankTrial': [False, False...</td>\n",
       "      <td>{'spikes': {'amps': [0.0012963217, 0.001194386...</td>\n",
       "      <td>{'spikes': {}, 'clusters': {}}</td>\n",
       "      <td>{'camera': {'times': [-7.773405105399037, -7.7...</td>\n",
       "      <td>{'camera': {'times': [-7.97343580861559, -7.94...</td>\n",
       "      <td>{'camera': {'times': [-7.77102351477709, -7.73...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-03-14</td>\n",
       "      <td>3</td>\n",
       "      <td>spontaneousActivity</td>\n",
       "      <td>5646</td>\n",
       "      <td>poppy-stim</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>\\\\zortex.cortexlab.net\\Subjects\\AV043\\2024-03-...</td>\n",
       "      <td>\\\\zortex.cortexlab.net\\Subjects\\AV043\\2024-03-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AV043</td>\n",
       "      <td>{'_av_trials': {}}</td>\n",
       "      <td>{'spikes': {'amps': [0.0011510205, 0.001252702...</td>\n",
       "      <td>{'spikes': {}, 'clusters': {}}</td>\n",
       "      <td>{'camera': {}}</td>\n",
       "      <td>{'camera': {}}</td>\n",
       "      <td>{'camera': {}}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      expDate expNum                             expDef expDuration  \\\n",
       "0  2024-03-14      1   multiSpaceWorld_checker_training        3576   \n",
       "1  2024-03-14      2  AVPassive_ckeckerboard_postactive        3386   \n",
       "2  2024-03-14      3                spontaneousActivity        5646   \n",
       "\n",
       "       rigName existBlock existTimeline existFrontCam existSideCam  \\\n",
       "0  zelda-stim1          1             1             1            1   \n",
       "1  zelda-stim1          1             1             1            1   \n",
       "2   poppy-stim          1             1             0            0   \n",
       "\n",
       "  existEyeCam  ...                                          expFolder  \\\n",
       "0           1  ...  \\\\zortex.cortexlab.net\\Subjects\\AV043\\2024-03-...   \n",
       "1           1  ...  \\\\zortex.cortexlab.net\\Subjects\\AV043\\2024-03-...   \n",
       "2           0  ...  \\\\zortex.cortexlab.net\\Subjects\\AV043\\2024-03-...   \n",
       "\n",
       "                                     ephysPathProbe0 ephysPathProbe1 subject  \\\n",
       "0  \\\\zortex.cortexlab.net\\Subjects\\AV043\\2024-03-...             NaN   AV043   \n",
       "1  \\\\zortex.cortexlab.net\\Subjects\\AV043\\2024-03-...             NaN   AV043   \n",
       "2  \\\\zortex.cortexlab.net\\Subjects\\AV043\\2024-03-...             NaN   AV043   \n",
       "\n",
       "                                              events  \\\n",
       "0  {'_av_trials': {'is_blankTrial': [False, False...   \n",
       "1  {'_av_trials': {'is_blankTrial': [False, False...   \n",
       "2                                 {'_av_trials': {}}   \n",
       "\n",
       "                                              probe0  \\\n",
       "0  {'spikes': {'amps': [0.0088954335, 0.001937999...   \n",
       "1  {'spikes': {'amps': [0.0012963217, 0.001194386...   \n",
       "2  {'spikes': {'amps': [0.0011510205, 0.001252702...   \n",
       "\n",
       "                           probe1  \\\n",
       "0  {'spikes': {}, 'clusters': {}}   \n",
       "1  {'spikes': {}, 'clusters': {}}   \n",
       "2  {'spikes': {}, 'clusters': {}}   \n",
       "\n",
       "                                            frontCam  \\\n",
       "0  {'camera': {'times': [-13.885303461488334, -13...   \n",
       "1  {'camera': {'times': [-7.773405105399037, -7.7...   \n",
       "2                                     {'camera': {}}   \n",
       "\n",
       "                                             sideCam  \\\n",
       "0  {'camera': {'times': [-13.9500134846031, -13.9...   \n",
       "1  {'camera': {'times': [-7.97343580861559, -7.94...   \n",
       "2                                     {'camera': {}}   \n",
       "\n",
       "                                              eyeCam  \n",
       "0  {'camera': {'ROIMotionEnergy': [119602.0, 1033...  \n",
       "1  {'camera': {'times': [-7.77102351477709, -7.73...  \n",
       "2                                     {'camera': {}}  \n",
       "\n",
       "[3 rows x 37 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recordings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utility functions\n",
    "There are numerous utility functions to process both event data `utils.ev_utils`, and spike data `utils.spike_utils`. Please brose those functions freely but be aware that at the moment they might change at times. \n",
    "For example you can `format_events` for the audiovisual events task ev structure (returning a `pd.df`) for more ideal processing in python.\n",
    "For spikes data you can use `format_cluster_data`, which will parse the anatomical location and the bombcell quality metrics of your units. \n",
    "(sorry it has some warning messages atm!)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Flora\\anaconda3\\envs\\test_packaging\\lib\\site-packages\\floras_helpers\\hist\\regions.py:430: RuntimeWarning: invalid value encountered in cast\n",
      "  level=df_regions.depth.to_numpy().astype(np.uint16),\n",
      "c:\\Users\\Flora\\anaconda3\\envs\\test_packaging\\lib\\site-packages\\floras_helpers\\hist\\regions.py:432: RuntimeWarning: invalid value encountered in cast\n",
      "  order=df_regions.graph_order.to_numpy().astype(np.uint16))\n",
      "c:\\Users\\Flora\\anaconda3\\envs\\test_packaging\\lib\\site-packages\\pinkrigs_tools\\utils\\spk_utils.py:172: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clusInfo.brainLocationAcronyms_ccf_2017[\n"
     ]
    }
   ],
   "source": [
    "from pinkrigs_tools.utils import ev_utils\n",
    "from pinkrigs_tools.utils import spk_utils\n",
    "\n",
    "example_active_session  = recordings[recordings.expDef=='multiSpaceWorld_checker_training'].iloc[0]\n",
    "\n",
    "\n",
    "ev = example_active_session.events._av_trials\n",
    "spikes = example_active_session.probe0.spikes\n",
    "clusters = example_active_session.probe0.clusters\n",
    "\n",
    "\n",
    "formatted_events = ev_utils.format_events(ev)\n",
    "\n",
    "formatted_cluster_data = spk_utils.format_cluster_data(clusters) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amps</th>\n",
       "      <th>channels</th>\n",
       "      <th>depths</th>\n",
       "      <th>peakToTrough</th>\n",
       "      <th>_av_IDs</th>\n",
       "      <th>_av_KSLabels</th>\n",
       "      <th>cluster_id</th>\n",
       "      <th>amp_max</th>\n",
       "      <th>amp_min</th>\n",
       "      <th>amp_median</th>\n",
       "      <th>...</th>\n",
       "      <th>fractionRPVs_estimatedTauR</th>\n",
       "      <th>ml</th>\n",
       "      <th>ap</th>\n",
       "      <th>dv</th>\n",
       "      <th>hemi</th>\n",
       "      <th>brainLocationAcronyms_ccf_2017</th>\n",
       "      <th>brainLocationIds_ccf_2017</th>\n",
       "      <th>bombcell_class</th>\n",
       "      <th>is_good</th>\n",
       "      <th>BerylAcronym</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000013</td>\n",
       "      <td>114</td>\n",
       "      <td>3410.024658</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.928764</td>\n",
       "      <td>10.075504</td>\n",
       "      <td>16.809126</td>\n",
       "      <td>...</td>\n",
       "      <td>0.129804</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>void</td>\n",
       "      <td>NaN</td>\n",
       "      <td>noise</td>\n",
       "      <td>False</td>\n",
       "      <td>void</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000017</td>\n",
       "      <td>114</td>\n",
       "      <td>3411.850098</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.050194</td>\n",
       "      <td>17.363848</td>\n",
       "      <td>22.537854</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019109</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>void</td>\n",
       "      <td>NaN</td>\n",
       "      <td>good</td>\n",
       "      <td>True</td>\n",
       "      <td>void</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000012</td>\n",
       "      <td>114</td>\n",
       "      <td>3417.616943</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>40.520416</td>\n",
       "      <td>10.953544</td>\n",
       "      <td>14.645905</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>void</td>\n",
       "      <td>NaN</td>\n",
       "      <td>noise</td>\n",
       "      <td>False</td>\n",
       "      <td>void</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000010</td>\n",
       "      <td>115</td>\n",
       "      <td>3420.000000</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>36.700035</td>\n",
       "      <td>10.030917</td>\n",
       "      <td>13.387458</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053901</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>void</td>\n",
       "      <td>NaN</td>\n",
       "      <td>good</td>\n",
       "      <td>True</td>\n",
       "      <td>void</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000010</td>\n",
       "      <td>114</td>\n",
       "      <td>3420.000000</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>31.295649</td>\n",
       "      <td>10.173931</td>\n",
       "      <td>13.363407</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035483</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>void</td>\n",
       "      <td>NaN</td>\n",
       "      <td>good</td>\n",
       "      <td>True</td>\n",
       "      <td>void</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>809</th>\n",
       "      <td>0.000011</td>\n",
       "      <td>160</td>\n",
       "      <td>4062.747314</td>\n",
       "      <td>-0.800000</td>\n",
       "      <td>809</td>\n",
       "      <td>1</td>\n",
       "      <td>809.0</td>\n",
       "      <td>41.456051</td>\n",
       "      <td>10.628459</td>\n",
       "      <td>14.232888</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>void</td>\n",
       "      <td>NaN</td>\n",
       "      <td>noise</td>\n",
       "      <td>False</td>\n",
       "      <td>void</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810</th>\n",
       "      <td>0.000012</td>\n",
       "      <td>159</td>\n",
       "      <td>4031.749268</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>810</td>\n",
       "      <td>1</td>\n",
       "      <td>810.0</td>\n",
       "      <td>87.187416</td>\n",
       "      <td>10.577412</td>\n",
       "      <td>15.149150</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>void</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mua</td>\n",
       "      <td>False</td>\n",
       "      <td>void</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811</th>\n",
       "      <td>0.000012</td>\n",
       "      <td>159</td>\n",
       "      <td>4054.438477</td>\n",
       "      <td>-0.233333</td>\n",
       "      <td>811</td>\n",
       "      <td>1</td>\n",
       "      <td>811.0</td>\n",
       "      <td>45.722466</td>\n",
       "      <td>11.319118</td>\n",
       "      <td>15.070586</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>void</td>\n",
       "      <td>NaN</td>\n",
       "      <td>noise</td>\n",
       "      <td>False</td>\n",
       "      <td>void</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812</th>\n",
       "      <td>0.000023</td>\n",
       "      <td>159</td>\n",
       "      <td>4020.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>812</td>\n",
       "      <td>2</td>\n",
       "      <td>812.0</td>\n",
       "      <td>56.394169</td>\n",
       "      <td>24.596430</td>\n",
       "      <td>30.475230</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>void</td>\n",
       "      <td>NaN</td>\n",
       "      <td>good</td>\n",
       "      <td>True</td>\n",
       "      <td>void</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>0.000013</td>\n",
       "      <td>160</td>\n",
       "      <td>4048.880371</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>813</td>\n",
       "      <td>1</td>\n",
       "      <td>813.0</td>\n",
       "      <td>86.944336</td>\n",
       "      <td>10.461029</td>\n",
       "      <td>15.158863</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>void</td>\n",
       "      <td>NaN</td>\n",
       "      <td>noise</td>\n",
       "      <td>False</td>\n",
       "      <td>void</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>814 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         amps  channels       depths  peakToTrough  _av_IDs  _av_KSLabels  \\\n",
       "0    0.000013       114  3410.024658      0.566667        0             2   \n",
       "1    0.000017       114  3411.850098      0.633333        1             2   \n",
       "2    0.000012       114  3417.616943      1.100000        2             1   \n",
       "3    0.000010       115  3420.000000      0.566667        3             2   \n",
       "4    0.000010       114  3420.000000      0.766667        4             1   \n",
       "..        ...       ...          ...           ...      ...           ...   \n",
       "809  0.000011       160  4062.747314     -0.800000      809             1   \n",
       "810  0.000012       159  4031.749268      0.733333      810             1   \n",
       "811  0.000012       159  4054.438477     -0.233333      811             1   \n",
       "812  0.000023       159  4020.000000      0.666667      812             2   \n",
       "813  0.000013       160  4048.880371      0.833333      813             1   \n",
       "\n",
       "     cluster_id    amp_max    amp_min  amp_median  ...  \\\n",
       "0           0.0  28.928764  10.075504   16.809126  ...   \n",
       "1           1.0  38.050194  17.363848   22.537854  ...   \n",
       "2           2.0  40.520416  10.953544   14.645905  ...   \n",
       "3           3.0  36.700035  10.030917   13.387458  ...   \n",
       "4           4.0  31.295649  10.173931   13.363407  ...   \n",
       "..          ...        ...        ...         ...  ...   \n",
       "809       809.0  41.456051  10.628459   14.232888  ...   \n",
       "810       810.0  87.187416  10.577412   15.149150  ...   \n",
       "811       811.0  45.722466  11.319118   15.070586  ...   \n",
       "812       812.0  56.394169  24.596430   30.475230  ...   \n",
       "813       813.0  86.944336  10.461029   15.158863  ...   \n",
       "\n",
       "     fractionRPVs_estimatedTauR  ml  ap  dv  hemi  \\\n",
       "0                      0.129804 NaN NaN NaN   NaN   \n",
       "1                      0.019109 NaN NaN NaN   NaN   \n",
       "2                      1.000000 NaN NaN NaN   NaN   \n",
       "3                      0.053901 NaN NaN NaN   NaN   \n",
       "4                      0.035483 NaN NaN NaN   NaN   \n",
       "..                          ...  ..  ..  ..   ...   \n",
       "809                    1.000000 NaN NaN NaN   NaN   \n",
       "810                    1.000000 NaN NaN NaN   NaN   \n",
       "811                    1.000000 NaN NaN NaN   NaN   \n",
       "812                    0.000000 NaN NaN NaN   NaN   \n",
       "813                    1.000000 NaN NaN NaN   NaN   \n",
       "\n",
       "     brainLocationAcronyms_ccf_2017  brainLocationIds_ccf_2017  \\\n",
       "0                              void                        NaN   \n",
       "1                              void                        NaN   \n",
       "2                              void                        NaN   \n",
       "3                              void                        NaN   \n",
       "4                              void                        NaN   \n",
       "..                              ...                        ...   \n",
       "809                            void                        NaN   \n",
       "810                            void                        NaN   \n",
       "811                            void                        NaN   \n",
       "812                            void                        NaN   \n",
       "813                            void                        NaN   \n",
       "\n",
       "     bombcell_class  is_good  BerylAcronym  \n",
       "0             noise    False          void  \n",
       "1              good     True          void  \n",
       "2             noise    False          void  \n",
       "3              good     True          void  \n",
       "4              good     True          void  \n",
       "..              ...      ...           ...  \n",
       "809           noise    False          void  \n",
       "810             mua    False          void  \n",
       "811           noise    False          void  \n",
       "812            good     True          void  \n",
       "813           noise    False          void  \n",
       "\n",
       "[814 rows x 57 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_cluster_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neurometric criteria of data selection\n",
    "(takes a long time!)\n",
    "Sometimes, you just want to call experimental sessions with neural data from a specific brain region, or ensure that each session you are calling is from a separate brain region. `load_data` can also handle that for you with some of its arguments that specifically relate to neural data. More broadly we deal with: \n",
    "- several probes per recordings: \n",
    "    - you can use the `unwrap_probes` argument to flatten the recordings DataFrame such that each probe is a separate row. In this case the neural data is merged under the `probe` column and the `probeID` column will contain info about which probe each row corresponds to (`probe0` or `probe1` on the ONE folder)\n",
    "    - you can also use the `merge_probes` to instead not create a sepatate row but just re-ID the clusters (adding 1000 to probe1 clusterIDs)\n",
    "- chronic recordings: \n",
    "    - `filter_unique_shank_positions` where we only allow each botrow position to be sampled once\n",
    "- region selection\n",
    "    to load experiments only when minimum 10 neurons etc. are in a particular brain region defined by Allen Acronyms. \n",
    "\n",
    "For Example the below code loads in all the data with minimum 20 neurons in MRN in `AV030`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Flora\\anaconda3\\envs\\test_packaging\\lib\\site-packages\\floras_helpers\\hist\\regions.py:430: RuntimeWarning: invalid value encountered in cast\n",
      "  level=df_regions.depth.to_numpy().astype(np.uint16),\n",
      "c:\\Users\\Flora\\anaconda3\\envs\\test_packaging\\lib\\site-packages\\floras_helpers\\hist\\regions.py:432: RuntimeWarning: invalid value encountered in cast\n",
      "  order=df_regions.graph_order.to_numpy().astype(np.uint16))\n"
     ]
    }
   ],
   "source": [
    "exp_kwargs = {\n",
    "    'subject': ['AV030'],\n",
    "    'expDate': 'postImplant',\n",
    "    'expDef': 'multiSpaceWorld'\n",
    "    }\n",
    "recordings = load_data(data_name_dict = 'all-default',\n",
    "                             unwrap_probes= False,\n",
    "                             merge_probes=True,\n",
    "                             filter_unique_shank_positions = False,\n",
    "                             region_selection={'region_name':'MRN',\n",
    "                                                'framework':'Beryl',\n",
    "                                                'min_fraction':20,\n",
    "                                                'goodOnly':True,\n",
    "                                                'min_spike_num':300},\n",
    "                            **exp_kwargs\n",
    "                             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Call and save out pre-curated datasets \n",
    "Oftentimes I use neurometric criteria, but because it takes a long time, you want to compte the experiments that you want to analyse once, and then you can load just those experiments. For this, I also wrote a function (`dataset.pre_cured.call_`) to call just predtermined fdatasets where I aleady set up the selection criteria. With this, you save your selection in your `analysis_folder` and load summary data with the latest timestamp. You can recompute your selection using the `recompute_data_selection` argument. For example, with the below code will call all the data where mice were recorded in the forebrain while doing the audiovisual task.\n",
    "\n",
    "(not ready) You can also use `extract. ...` to save out the trial data with spiking and movement. \n",
    "\n",
    "(not ready) You can also use `extract. ...` to save out the binned time series, which contains binned neural,camera and event data and event triggered toeplitz matrices. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from pinkrigs_tools.dataset.pre_cured import call_\n",
    "\n",
    "\n",
    "analysis_folder = Path(r'path_to_analysis_folder')\n",
    "\n",
    "recordings = call_(subject_set='forebrain',\n",
    "                             dataset_type='active',\n",
    "                             spikeToInclde=True,\n",
    "                             camToInclude=False,\n",
    "                             recompute_data_selection = False,\n",
    "                             unwrap_probes= True,\n",
    "                             merge_probes=False,\n",
    "                             region_selection=None,\n",
    "                             filter_unique_shank_positions = True,\n",
    "                             analysis_folder = analysis_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_packaging",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
