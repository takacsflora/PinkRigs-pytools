{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataSet structure\n",
    "The main thing to know about the PinkRigs organisation is that we store two types of data about the experiments: \n",
    "- metadata (CSVs) summarising each animal and experiemntal session\n",
    "- experimental session data\n",
    "Typically when you run analysis on the PinkRigs data you will need to do the following: \n",
    "1) query the metadata to make sure you included all the data that fits your requrements\n",
    "2) load in the details (events,spikes,cameras) of the datasets that you have selected\n",
    "\n",
    "\n",
    "### Querying experiments\n",
    "You can query the experiements using the `query.queryCSV` module, e.g.:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.query import queryCSV\n",
    "\n",
    "exp = queryCSV(\n",
    "  subject='AV043',\n",
    "  expDate='2024-03-14:2024-03-24', \n",
    "  expDef = 'multiSpaceWorld_checker_training',\n",
    "  )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data\n",
    "You can also direcrly query and then load the ONE folder content in one line using `load_data`. To specify the ONE folder content to load, you need to give a nested dictionary to the `data_name_dict` argument of the `load_data`. The nesting follows the ONE data structure `{collection:{'object':'attribute'}}`. For example: \n",
    "#### Events data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.query import load_data\n",
    "\n",
    "# define parameters of your query\n",
    "exp_kwargs = {\n",
    "    'subject': ['AV043'],\n",
    "    'expDate': '2024-03-14:2024-03-15',\n",
    "    }\n",
    "\n",
    "# define the ONE data to load\n",
    "data_name_dict = { 'events': {'_av_trials': 'table'}}\n",
    "recordings = load_data(data_name_dict=data_name_dict,**exp_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spikes data\n",
    "(this operation is the slowest! So, in order to avoid loading in unwanted data, you should probably query the data first and then only load in spike data for datasets that you ensured you want to use in your analysis.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ephys_dict = {'spikes':'all','clusters':'all'}\n",
    "# both probes \n",
    "data_name_dict = {'probe0':ephys_dict,'probe1':ephys_dict} \n",
    "recordings = load_data(data_name_dict=data_name_dict,**exp_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Camera data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cameras = ['frontCam','sideCam','eyeCam']\n",
    "data_name_dict = {cam:{'camera':['times','ROIMotionEnergy']} for cam in cameras}\n",
    "recordings = load_data(data_name_dict=data_name_dict,**exp_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively you can also first query the data using `queryCSV`, subset your DataFrame as you wish, and load the ONE object only on your subset using 'load_data'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "recordings = load_data(recordings=exp.iloc[0:1], data_name_dict = {'events':{'_av_trials':'all'}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or just load every data together! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define which data you need\n",
    "\n",
    "# for example events (auditory trial onset etc.)\n",
    "data_name_dict = { 'events': {'_av_trials': 'table'}}\n",
    "\n",
    "# if you want ephys data\n",
    "ephys_dict = {'spikes':'all','clusters':'all'}\n",
    "# both probes \n",
    "ephys_dict = {'probe0':ephys_dict,'probe1':ephys_dict} \n",
    "data_name_dict.update(ephys_dict)\n",
    "\n",
    "# camera data\n",
    "cameras = ['frontCam','sideCam','eyeCam']\n",
    "cam_dict = {cam:{'camera':['times','ROIMotionEnergy']} for cam in cameras}\n",
    "data_name_dict.update(cam_dict)\n",
    "\n",
    "\n",
    "exp_kwargs = {\n",
    "    'subject': ['AV043'],\n",
    "    'expDate': '2024-03-14',\n",
    "    'expNum': '1'\n",
    "    }\n",
    "\n",
    "\n",
    "recordings = load_data(data_name_dict=data_name_dict,**exp_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neurometric criteria of data selection\n",
    "(takes a long time!)\n",
    "Sometimes, you just want to call experimental sessions with neural data from a specific brain region, or ensure that each session you are calling is from a separate brain region. `load_data` can also handle that for you with some of its arguments that specifically relate to neural data. More broadly we deal with: \n",
    "- several probes per recordings: \n",
    "    - you can use the `unwrap_probes` argument to flatten the recordings DataFrame such that each probe is a separate row. In this case the neural data is merged under the `probe` column and the `probeID` column will contain info about which probe each row corresponds to (`probe0` or `probe1` on the ONE folder)\n",
    "    - you can also use the `merge_probes` to instead not create a sepatate row but just re-ID the clusters (adding 1000 to probe1 clusterIDs)\n",
    "- chronic recordings: \n",
    "    - `filter_unique_shank_positions` where we only allow each botrow position to be sampled once\n",
    "- region selection\n",
    "    to load experiments only when minimum 10 neurons etc. are in a particular brain region defined by Allen Acronyms. \n",
    "\n",
    "For Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Flora\\anaconda3\\envs\\neural_encoding\\lib\\site-packages\\utils\\spk_utils.py:52: RuntimeWarning: invalid value encountered in less_equal\n",
      "  (clusdat.percentageSpikesMissing_gaussian <= max_percentage_spikes_missing) &\n",
      "c:\\Users\\Flora\\anaconda3\\envs\\neural_encoding\\lib\\site-packages\\floras_helpers\\hist\\regions.py:430: RuntimeWarning: invalid value encountered in cast\n",
      "  level=df_regions.depth.to_numpy().astype(np.uint16),\n",
      "c:\\Users\\Flora\\anaconda3\\envs\\neural_encoding\\lib\\site-packages\\floras_helpers\\hist\\regions.py:432: RuntimeWarning: invalid value encountered in cast\n",
      "  order=df_regions.graph_order.to_numpy().astype(np.uint16))\n",
      "c:\\Users\\Flora\\anaconda3\\envs\\neural_encoding\\lib\\site-packages\\utils\\spk_utils.py:54: RuntimeWarning: invalid value encountered in greater_equal\n",
      "  (clusdat.presenceRatio >= min_presence_ratio)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'clusters'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m exp_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubject\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAV030\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexpDate\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpostImplant\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      4\u001b[0m     }\n\u001b[1;32m----> 6\u001b[0m recordings \u001b[38;5;241m=\u001b[39m load_data(data_name_dict \u001b[38;5;241m=\u001b[39m data_name_dict,\n\u001b[0;32m      7\u001b[0m                              unwrap_probes\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m      8\u001b[0m                              merge_probes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m      9\u001b[0m                              filter_unique_shank_positions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     10\u001b[0m                              region_selection\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mregion_name\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMRN\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     11\u001b[0m                                                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mframework\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBeryl\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     12\u001b[0m                                                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin_fraction\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m20\u001b[39m,\n\u001b[0;32m     13\u001b[0m                                                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgoodOnly\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     14\u001b[0m                                                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin_spike_num\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m300\u001b[39m},\n\u001b[0;32m     15\u001b[0m                             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mexp_kwargs\n\u001b[0;32m     16\u001b[0m                              )\n",
      "File \u001b[1;32mc:\\Users\\Flora\\anaconda3\\envs\\neural_encoding\\lib\\site-packages\\dataset\\query.py:440\u001b[0m, in \u001b[0;36mload_data\u001b[1;34m(recordings, data_name_dict, unwrap_probes, merge_probes, region_selection, filter_unique_shank_positions, cam_hierarchy, **kwargs)\u001b[0m\n\u001b[0;32m    434\u001b[0m         \u001b[38;5;66;03m# first we identify whether there are two probes\u001b[39;00m\n\u001b[0;32m    435\u001b[0m         \u001b[38;5;66;03m# then we process the 2nd probes data such that it can be disambiguated from the first probe\u001b[39;00m\n\u001b[0;32m    436\u001b[0m         \u001b[38;5;66;03m# process the 1st probe\u001b[39;00m\n\u001b[0;32m    437\u001b[0m         \u001b[38;5;66;03m# merge\u001b[39;00m\n\u001b[0;32m    439\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m region_selection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 440\u001b[0m         keep_rec_region \u001b[38;5;241m=\u001b[39m [is_rec_in_region(rec, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mregion_selection) \u001b[38;5;28;01mfor\u001b[39;00m _, rec \u001b[38;5;129;01min\u001b[39;00m recordings\u001b[38;5;241m.\u001b[39miterrows()]\n\u001b[0;32m    441\u001b[0m         recordings \u001b[38;5;241m=\u001b[39m recordings[keep_rec_region]\n\u001b[0;32m    443\u001b[0m \u001b[38;5;66;03m# give each recording a unique ID\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Flora\\anaconda3\\envs\\neural_encoding\\lib\\site-packages\\dataset\\query.py:440\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    434\u001b[0m         \u001b[38;5;66;03m# first we identify whether there are two probes\u001b[39;00m\n\u001b[0;32m    435\u001b[0m         \u001b[38;5;66;03m# then we process the 2nd probes data such that it can be disambiguated from the first probe\u001b[39;00m\n\u001b[0;32m    436\u001b[0m         \u001b[38;5;66;03m# process the 1st probe\u001b[39;00m\n\u001b[0;32m    437\u001b[0m         \u001b[38;5;66;03m# merge\u001b[39;00m\n\u001b[0;32m    439\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m region_selection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 440\u001b[0m         keep_rec_region \u001b[38;5;241m=\u001b[39m [is_rec_in_region(rec, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mregion_selection) \u001b[38;5;28;01mfor\u001b[39;00m _, rec \u001b[38;5;129;01min\u001b[39;00m recordings\u001b[38;5;241m.\u001b[39miterrows()]\n\u001b[0;32m    441\u001b[0m         recordings \u001b[38;5;241m=\u001b[39m recordings[keep_rec_region]\n\u001b[0;32m    443\u001b[0m \u001b[38;5;66;03m# give each recording a unique ID\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Flora\\anaconda3\\envs\\neural_encoding\\lib\\site-packages\\utils\\spk_utils.py:109\u001b[0m, in \u001b[0;36mis_rec_in_region\u001b[1;34m(rec, region_name, framework, min_fraction, goodOnly, **bombcell_kwargs)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_rec_in_region\u001b[39m(rec, region_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSC\u001b[39m\u001b[38;5;124m'\u001b[39m, framework\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mccf\u001b[39m\u001b[38;5;124m'\u001b[39m, min_fraction\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m.1\u001b[39m, goodOnly\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mbombcell_kwargs):\n\u001b[0;32m     89\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;124;03m    utility function to assess whether a recording contains neurons in a target region\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;124;03m        whether rec is in region with region_name or not \u001b[39;00m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 109\u001b[0m     clusters \u001b[38;5;241m=\u001b[39m \u001b[43mrec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprobe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclusters\u001b[49m\n\u001b[0;32m    110\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m goodOnly:\n\u001b[0;32m    111\u001b[0m         bc_class \u001b[38;5;241m=\u001b[39m bombcell_sort_units(clusters, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mbombcell_kwargs)  \u001b[38;5;66;03m# %%\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'float' object has no attribute 'clusters'"
     ]
    }
   ],
   "source": [
    "exp_kwargs = {\n",
    "    'subject': ['AV030'],\n",
    "    'expDate': 'postImplant',\n",
    "    }\n",
    "\n",
    "recordings = load_data(data_name_dict = data_name_dict,\n",
    "                             unwrap_probes= False,\n",
    "                             merge_probes=True,\n",
    "                             filter_unique_shank_positions = False,\n",
    "                             region_selection={'region_name':'MRN',\n",
    "                                                'framework':'Beryl',\n",
    "                                                'min_fraction':20,\n",
    "                                                'goodOnly':True,\n",
    "                                                'min_spike_num':300},\n",
    "                            **exp_kwargs\n",
    "                             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Call predtermined datasets \n",
    "Oftentimes I use neurometric criteria, but because it takes a long time, you want to compte the experiments that you want to analyse once, and then you can load just those experiments. For this, I also wrote a function ('dataset.pre_cured.call_') to call just predtermined fdatasets where I aleady set up the selection criteria. With this, you save your selection in your 'analysis_folder' and load summary data with the latest timestamp. You can recompute your selection using the 'recompute_data_selection' argument. For example, with the below code will call all the data where mice were recorded in the forebrain while doing the audiovisual task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from dataset.pre_cured import call_\n",
    "\n",
    "recordings = call_(subject_set='forebrain',\n",
    "                             dataset_type='active',\n",
    "                             spikeToInclde=True,\n",
    "                             camToInclude=False,\n",
    "                             recompute_data_selection=False,\n",
    "                             unwrap_probes= True,\n",
    "                             merge_probes=False,\n",
    "                             region_selection=None,\n",
    "                             filter_unique_shank_positions = True,\n",
    "                             analysis_folder = Path(r'D:\\ccCP\\forebrain'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neural_encoding",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
